---
title: "Lab 02"
output: html_document
---

```{r, include=FALSE, message=FALSE}
library(tidyverse)
library(ggrepel)
library(smodels)
library(stringi)
library(Matrix)
library(glmnet)
library(cleanNLP)
library(magrittr)

theme_set(theme_minimal())
options(dplyr.summarise.inform = FALSE)
```

## Diamonds

Here, we will apply the methods shown in the notes to a data set of diamonds.
This is a classic statistics data set used in a lot of notes that you may
find online. Our variable of interest is the price of each diamond.

```{r, message=FALSE}
set.seed(1)

diamond <- read_csv(file.path("data", "diamonds.csv")) %>%
  mutate(train_id = if_else(runif(n()) < 0.6, "train", "valid"))
diamond
```

Start by creating a scatter plot with carat on the x-axis and price on the
y-axis.

```{r, question-01}

```

Before we start building predictive models, it is good to have a baseline for
a good RMSE. Compute the RMSE on the train and valid sets using a model that
just takes the mean value of `price`.

```{r, question-02}

```

Now, buimd a model that predicts price as a function of a diamond's carat on
the training set. Calculate the RMSE for the training and validation sets.

```{r, question-03}

```

These should be almost half the size of the RMSE you had for the constant
model.

Now, add color (a categorical variable) into the model and compute the RMSE.

```{r, question-04}

```

Does the RMSE improve? **Answer**:

Now, print a summary of the model you just created.

```{r, question-05}
```

For a given size, what color seems to be the most expensive? **Answer**

Now, fit a model that uses carat and clarity to predict the price of a diamond.
Compute the RMSE of this model and compare to the previous two models.

```{r, question-06}

```

Modify the previous model to include a different slope and interecept for each
clarity. Again, compute the RMSE.

```{r, question-07}

```

Takign the model from the previous question, predict prices for all of the
diamands and plot the fit on a plot with carat on the x-axis, price on the
y-axis, and lines colored by clarity. Verify that the lines have different
slopes and intercepts.

```{r, question-08}

```

The relationship between carat and price seems non-linear. Fit a linear
regression using a 5th order polynomial of carat to predict the price of a
diamond. Print out the RMSE.

```{r, question-09}

```

Plot the fit from the previous model (a scatter plot with a line through the
data showing the fitted values). Verify that the fit is non-linear.

```{r, question-10}

```

The 4 C's that determine a diamond's prices are: cut, color, clarity, and
carat (weight). Build a model that uses these four variables to predict the
price of a diamon and print out the RMSE.

```{r, question-11}

```

Finally, take the model from the previous question and change all of the pluses
into `*` to create a four-way interaction. This has a different slope and
intercept for each combination of all three variables. Print out the RMSE
for the train and validation sets.

```{r, warning=FALSE, question-12}

```

What do you notice here? **Answer**

## Cars

As a second data set, we will look at another class statistical programming
data set of car models. The variable of interest is called `cty`, the fuel
efficiency of the car in city traffic (miles per gallon).

```{r, message=FALSE}
set.seed(1)

mpg <- read_csv(file.path("data", "mpg.csv")) %>%
  mutate(train_id = if_else(runif(n()) < 0.6, "train", "valid"))
mpg
```

### Predicting with hwy

One variable in the data set is called `hwy`. It gives the fuel effiency for a
car driving on the highway. As you might expect, this is a very good predictor
of a car's fuel efficiency in the city. To start, let's get the RMSE of a model
that just uses the mean of the `cty` variable for prediction.

```{r, question-13}

```

Now fit a model on the training data where the highway fuel efficency is used
to predict the city fuel efficency. Print out a summary of the model.

```{r, question-14}

```

According to the model, do you expect the city fuel efficiency to be higher in
the city or the highway? **Answer**



```{r, question-15}

```

Now, compute the RMSE of this model. Verify that it is much lower than the
constant model.

```{r, question-16}

```

Now, let's try to re-fit this model using the matrix notation in R. To start,
create a model matrix `X` and response vector `y` based on the same model you
fit above. Print the head of the matrix.

```{r, question-17}

```

Now, create a training design matrix and response vector.

```{r, question-18}

```

And fit the regression using `lm.fit`. Verify that the coefficients are
very close (up to rounding) to the model you had from the `lm` function.

```{r, question-19}

```

And then re-compute the RMSE to verify that it is the same as in the previous
model.

```{r, question-20}

```
Finally, just to show that it is possible, use the matrix product formulation
at the bottom of my notes to show that you again get the same coefficients.

```{r, question-21}

```

### Predicting with engine size (displ)

For one last model, create a scatter plot with the variable `displ` (the engine
displacement; you can think of it as the size of the engine) on the x-axis and
the city fuel efficency on the y-axis.

```{r, question-22}

```

You should notice that the relationship is non-linear. Fit a regression model
predicting city fuel efficiency with the engine displacement using a 4th order
polynomial expansion. Print out the model coefficients.

```{r, question-23}

```

Now, plot the model fit to verify that it visually fits the data well.

```{r, question-24}

```

It will also be interesting to add in a categorical variable. Fit a regression
model predicting city fuel efficiency with the engine displacement using a 4th
order polynomial expansion and include the categorical variable drv. Print out
the model coefficients.

```{r, question-25}

```

As in the previous section, we are going to try to produce a model matrix
to fit the same model using `lm.fit`. Start by creating the model matrix and
response vector:

```{r, question-26}

```

Then create a model matrix and response vector just for the training set.

```{r, question-27}

```

And fit the regression using `lm.fit`.

```{r, question-28}

```

Look at the coefficients and compare to the ones in the model with with `lm()`.
They are not the same! The last two are, but the others are all different.
Compute the RMSE of the model:

```{r, question-29}

```

Confusingly, this **is** the same. What's going on here?!

Run the code below to see the matrix product XtX, rounded to 10 decimal places:

```{r}
round(crossprod(X), 10)
```

What happens is that when R creates a polynomial expansion it uses an algorithm
to ensure that the polynomial coefficients are uncorrelated. This is much more
numerically stable than using, say, x, x^2, x^3, and so forth. In our
formulation here the difference is that in lm() the polynomials were designed
to be orthogonal on the training data; in the formulation here they are
orthogonal on the entire data set. The fitted values are the same (it is still
just a 4th order expansion), but the specific beta values are different.
